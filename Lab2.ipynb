{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@varlamov @McFaul –ù–∞</td>\n",
       "      <td>skip</td>\n",
       "      <td>1327934765807308801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1252943181387350017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1323610669061677056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1336231661160247297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1292421736454127617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0                               @varlamov @McFaul –ù–∞      skip   \n",
       "1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "\n",
       "                    id  \n",
       "0  1327934765807308801  \n",
       "1  1252943181387350017  \n",
       "2  1323610669061677056  \n",
       "3  1336231661160247297  \n",
       "4  1292421736454127617  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/rusentitweet_full.csv\")\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value = len(df[\"label\"].unique())\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['skip', 'negative', 'neutral', 'speech', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>int_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@varlamov @McFaul –ù–∞</td>\n",
       "      <td>skip</td>\n",
       "      <td>1327934765807308801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1252943181387350017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1323610669061677056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1336231661160247297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1292421736454127617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0                               @varlamov @McFaul –ù–∞      skip   \n",
       "1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "\n",
       "                    id  int_labels  \n",
       "0  1327934765807308801           0  \n",
       "1  1252943181387350017           1  \n",
       "2  1323610669061677056           1  \n",
       "3  1336231661160247297           2  \n",
       "4  1292421736454127617           2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_label_to_int(label):\n",
    "    match label:\n",
    "        case 'skip':\n",
    "            label = label.replace('skip', '0')\n",
    "        case 'negative':\n",
    "            label = label.replace('negative', '1')\n",
    "        case 'neutral':\n",
    "            label = label.replace('neutral', '2')\n",
    "        case 'speech':\n",
    "            label = label.replace('speech', '3')\n",
    "        case 'positive':\n",
    "            label = label.replace('positive', '4')\n",
    "    return label\n",
    "\n",
    "df['int_labels'] = [change_label_to_int(t) for t in df['label']]\n",
    "df['int_labels'] = df['int_labels'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>int_labels</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@varlamov @McFaul –ù–∞</td>\n",
       "      <td>skip</td>\n",
       "      <td>1327934765807308801</td>\n",
       "      <td>0</td>\n",
       "      <td>tagged tagged –Ω–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1252943181387350017</td>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å–µ —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1323610669061677056</td>\n",
       "      <td>1</td>\n",
       "      <td>—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä–µ–º–Ω–∞—è—Å –∞—Ä—Ç–µ–º az...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1336231661160247297</td>\n",
       "      <td>2</td>\n",
       "      <td>–æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã  link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1292421736454127617</td>\n",
       "      <td>2</td>\n",
       "      <td>tagged tagged –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ–∞ —Ç–∞–º –¥—Ä—É...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0                               @varlamov @McFaul –ù–∞      skip   \n",
       "1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "\n",
       "                    id  int_labels  \\\n",
       "0  1327934765807308801           0   \n",
       "1  1252943181387350017           1   \n",
       "2  1323610669061677056           1   \n",
       "3  1336231661160247297           2   \n",
       "4  1292421736454127617           2   \n",
       "\n",
       "                                      processed_text  \n",
       "0                                   tagged tagged –Ω–∞  \n",
       "1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å–µ —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  \n",
       "2  —Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä–µ–º–Ω–∞—è—Å –∞—Ä—Ç–µ–º az...  \n",
       "3              –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã  link  \n",
       "4  tagged tagged –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ–∞ —Ç–∞–º –¥—Ä—É...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('\\r', '')\n",
    "    text = text.lower()\n",
    "    text = text.replace('—ë', \"–µ\")\n",
    "    text = re.sub('@[^\\s]+','tagged', text)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','link', text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9–ê-–Ø–∞-—è ]\",\"\", text)\n",
    "    return text\n",
    "\n",
    "df['processed_text'] = [process_text(t) for t in df['text']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_labels</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tagged tagged –Ω–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å–µ —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä–µ–º–Ω–∞—è—Å –∞—Ä—Ç–µ–º az...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>–æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã  link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>tagged tagged –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ–∞ —Ç–∞–º –¥—Ä—É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13387</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤—Å–µ –ø–æ—Ä–∞ —Å–ø–∞—Ç—å –ø–∏–∑–¥–µ—Ü —Å–ª–æ–≤–∏–ª–∞ —à–∏–∑—É</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13388</th>\n",
       "      <td>2</td>\n",
       "      <td>—Ç–∞–∫–∏–º–∏ —Ç–µ–º–ø–∞–º–∏ —è —Å–æ–∑–¥–∞–º –Ω–æ–≤—É—é —Å–µ–∫—Ç—É –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13389</th>\n",
       "      <td>2</td>\n",
       "      <td>—Ç—ã —Å–º–æ—Ç—Ä–µ–ª–∞ –∞–Ω–∏–º–µ –∑–∞–≤–µ—Ä–Ω—É–≤—à–∏—Å—å –≤ –æ–¥–µ—è–ª–æ –ø–æ–∫–∞ –º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>1</td>\n",
       "      <td>tagged –ø–∏–∑–¥–∞–Ω—É—Ç—å—Å—è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>0</td>\n",
       "      <td>–∞–∫—Ü–∏—è –±–∏–±–ª–∏–æ–Ω–æ—á—å  2020 –ª–∏—Å—é—Ç–∫–∏–Ω–∞ –∞ —á–∏—Ç–∞–µ—Ç —Å—Ç–∏—Ö...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13392 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       int_labels                                     processed_text\n",
       "0               0                                   tagged tagged –Ω–∞\n",
       "1               1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å–µ —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...\n",
       "2               1  —Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä–µ–º–Ω–∞—è—Å –∞—Ä—Ç–µ–º az...\n",
       "3               2              –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã  link\n",
       "4               2  tagged tagged –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ–∞ —Ç–∞–º –¥—Ä—É...\n",
       "...           ...                                                ...\n",
       "13387           1                 –≤—Å–µ –ø–æ—Ä–∞ —Å–ø–∞—Ç—å –ø–∏–∑–¥–µ—Ü —Å–ª–æ–≤–∏–ª–∞ —à–∏–∑—É\n",
       "13388           2  —Ç–∞–∫–∏–º–∏ —Ç–µ–º–ø–∞–º–∏ —è —Å–æ–∑–¥–∞–º –Ω–æ–≤—É—é —Å–µ–∫—Ç—É –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏...\n",
       "13389           2  —Ç—ã —Å–º–æ—Ç—Ä–µ–ª–∞ –∞–Ω–∏–º–µ –∑–∞–≤–µ—Ä–Ω—É–≤—à–∏—Å—å –≤ –æ–¥–µ—è–ª–æ –ø–æ–∫–∞ –º...\n",
       "13390           1                                 tagged –ø–∏–∑–¥–∞–Ω—É—Ç—å—Å—è\n",
       "13391           0  –∞–∫—Ü–∏—è –±–∏–±–ª–∏–æ–Ω–æ—á—å  2020 –ª–∏—Å—é—Ç–∫–∏–Ω–∞ –∞ —á–∏—Ç–∞–µ—Ç —Å—Ç–∏—Ö...\n",
       "\n",
       "[13392 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('id', axis=1)\n",
    "df = df.drop('text', axis=1)\n",
    "df = df.drop('label', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased\",\n",
    "    do_lower_case = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96616a1c852419f9a2644949f3ec482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/l3xxxa/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    res = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=32,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return pd.Series([res[\"input_ids\"], res[\"attention_mask\"]])\n",
    "\n",
    "df[[\"input_ids\", \"attention_mask\"]] = df[\"processed_text\"].progress_apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "batch_size = 16\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=test_size,\n",
    "    shuffle=True,\n",
    "    stratify=df[\"int_labels\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(torch.cat(list(train_df[\"input_ids\"].values), dim=0),\n",
    "                          torch.cat(list(train_df[\"attention_mask\"].values), dim=0), \n",
    "                          torch.tensor(train_df[\"int_labels\"].values))\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            batch_size=batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = TensorDataset(torch.cat(list(test_df[\"input_ids\"].values), dim=0),\n",
    "                         torch.cat(list(test_df[\"attention_mask\"].values), dim=0), \n",
    "                         torch.tensor(test_df[\"int_labels\"].values))\n",
    "test_dataloader = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased\",\n",
    "    num_labels = max_value,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ö–∞–∫ —è –ø–æ–Ω—è–ª, –º—ã –¥–æ–ª–∂–Ω—ã –≤–∑—è—Ç—å –º–æ–¥–µ–ª—å –∏ —Ñ—É–Ω–∫—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è –∏–∑ –ø—Ä–∏–º–µ—Ä–∞. –Ω–∞ 5 —ç–ø–æ—Ö–∞—Ö, –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –≥–¥–µ-—Ç–æ –æ–∫–æ–ª–æ 4 —á–∞—Å–æ–≤ (1 —ç–ø–æ—Ö–∞ –≤ —Å—Ä–µ–¥–Ω–µ–º —Ç—Ä–∞—Ç–∏—Ç –æ–∫–æ–ª–æ 50 –º–∏–Ω—É—Ç). –ü—Ä–∏ —ç—Ç–æ–º —ç—Ç–æ –≤ –∏–¥–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö, —Å —É—á–µ—Ç–æ–º, —á—Ç–æ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –Ω–µ –∑–∞–∫–æ–Ω—á–∏—Ç—Å—è —Å–≤–∞–ø, –∏ –æ—Å—å –Ω–µ –ø—Ä–∏–±—å–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å, –∫–æ—Ç–æ—Ä—ã–π —Ç–∞–∫ –Ω–∞–≥–ª–æ –Ω–∞—á–∞–ª –∂—Ä–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9713a71d0a433193259d23a8d602b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d26d2d440340b897916aa479b7c69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr = 5e-6,\n",
    "    eps = 1e-08\n",
    ")\n",
    "\n",
    "for _ in tqdm(range(epochs), desc='Epoch'):\n",
    "    model.train()\n",
    "    \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        \n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_f1 = []\n",
    "\n",
    "    for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "          eval_output = model(b_input_ids, \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "          \n",
    "        logits = eval_output.logits\n",
    "        y_pred = torch.argmax(logits, dim = -1)\n",
    "        \n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "        y_true = b_labels.to('cpu').numpy()\n",
    "\n",
    "        val_f1_value = f1_score(y_true, y_pred, average='macro')\n",
    "        val_f1.append(val_f1_value)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation F1-score: {:.4f}'.format(sum(val_f1)/len(val_f1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
